---
layout: post
title: "FFmpeg-iOSè·å–æ‘„åƒå¤´éº¦å…‹é£"
description: "Bison"
category: FFmpeg
headline: Discover the theme elements
tags: [FFmpegï¼Œè§†é¢‘å¼€å‘ï¼Œç›´æ’­sdkï¼ŒiOSå¼€å‘]
imagefeature: 
comments: true
featured: 
mathjax: true
path: /images
---

![FFmpeg_allluckly.cn.png](http://upload-images.jianshu.io/upload_images/671504-ada1e50c34918b9b.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)
[Macç¼–è¯‘ffmpegè·å–FFmpeg-iOS](http://blog.allluckly.cn/ffmpeg/ffmpeg1/)
[ffmpegçš„H.264è§£ç ](https://blog.allluckly.cn/ffmpeg/ffmpeg2/)
[FFmpeg-iOSæ¨æµå™¨çš„ç®€å•å°è£…](https://blog.allluckly.cn/ffmpeg/ffmpeg3/)

ä»Šå¤©å’±æ¥è®²è®²åœ¨iOS å¹³å°ä¸Šåˆ©ç”¨ffmpegè·å–åˆ°æ‘„åƒå¤´å’Œéº¦å…‹é£ï¼Œä»£ç å¾ˆå°‘ï¼Œåé¢å†åŠ ä¸ŠiOS è‡ªå¸¦çš„è·å–æ‘„åƒå¤´çš„ä¾‹å­;

## FFmpegè·å–æ‘„åƒå¤´éº¦å…‹é£
- é¦–å…ˆå¯¼å…¥å¿…è¦çš„å¤´æ–‡ä»¶

```
#include <stdio.h>
#ifdef __cplusplus
extern "C"
{
#endif
#include <libavcodec/avcodec.h>
#include <libavformat/avformat.h>
#include <libswscale/swscale.h>
#include <libavdevice/avdevice.h>
    
#ifdef __cplusplus
};
#endif

```

å…·ä½“ä»£ç ç®€å•å°è£…äº†ä¸€ä¸‹ï¼Œå¦‚ä¸‹ï¼š

```
- (void)showDevice{
    avdevice_register_all();
    AVFormatContext *pFormatCtx = avformat_alloc_context();
    AVDictionary* options = NULL;
    av_dict_set(&options,"list_devices","true",0);
    AVInputFormat *iformat = av_find_input_format("avfoundation");
    printf("==AVFoundation Device Info===\n");
    avformat_open_input(&pFormatCtx,"",iformat,&options);
    printf("=============================\n");
    if(avformat_open_input(&pFormatCtx,"0",iformat,NULL)!=0){
        printf("Couldn't open input stream.\n");
        return ;
    }
    
}
```

è¿è¡Œä¸€ä¸‹å¯ä»¥çœ‹åˆ°æ—¥å¿—åŒºåŸŸçš„æ‰“å°ä¿¡æ¯å¦‚ä¸‹ï¼š

```
==AVFoundation Device Info===
2017-07-20 16:59:36.325150+0800 LBffmpegDemo[2040:821433] [MC] System group container for systemgroup.com.apple.configurationprofiles path is /private/var/containers/Shared/SystemGroup/systemgroup.com.apple.configurationprofiles
2017-07-20 16:59:36.326529+0800 LBffmpegDemo[2040:821433] [MC] Reading from public effective user settings.
[AVFoundation input device @ 0x145d0100] AVFoundation video devices:
[AVFoundation input device @ 0x145d0100] [0] Back Camera
[AVFoundation input device @ 0x145d0100] [1] Front Camera
[AVFoundation input device @ 0x145d0100] AVFoundation audio devices:
[AVFoundation input device @ 0x145d0100] [0] iPhone éº¦å…‹é£
=============================
[avfoundation @ 0x153ef800] Selected framerate (29.970030) is not supported by the device
[avfoundation @ 0x153ef800] Supported modes:
[avfoundation @ 0x153ef800]   192x144@[1.000000 30.000000]fps
[avfoundation @ 0x153ef800]   192x144@[1.000000 30.000000]fps
[avfoundation @ 0x153ef800]   352x288@[1.000000 30.000000]fps
[avfoundation @ 0x153ef800]   352x288@[1.000000 30.000000]fps
[avfoundation @ 0x153ef800]   480x360@[1.000000 30.000000]fps
[avfoundation @ 0x153ef800]   480x360@[1.000000 30.000000]fps
[avfoundation @ 0x153ef800]   640x480@[1.000000 30.000000]fps
[avfoundation @ 0x153ef800]   640x480@[1.000000 30.000000]fps
[avfoundation @ 0x153ef800]   960x540@[1.000000 30.000000]fps
[avfoundation @ 0x153ef800]   960x540@[1.000000 30.000000]fps
[avfoundation @ 0x153ef800]   1280x720@[1.000000 30.000000]fps
[avfoundation @ 0x153ef800]   1280x720@[1.000000 30.000000]fps
[avfoundation @ 0x153ef800]   1280x720@[1.000000 60.000000]fps
[avfoundation @ 0x153ef800]   1280x720@[1.000000 60.000000]fps
[avfoundation @ 0x153ef800]   1920x1080@[1.000000 30.000000]fps
[avfoundation @ 0x153ef800]   1920x1080@[1.000000 30.000000]fps
[avfoundation @ 0x153ef800]   2592x1936@[1.000000 20.000000]fps
[avfoundation @ 0x153ef800]   2592x1936@[1.000000 20.000000]fps
[avfoundation @ 0x153ef800]   3264x2448@[1.000000 20.000000]fps
[avfoundation @ 0x153ef800]   3264x2448@[1.000000 20.000000]fps
Couldn't open input stream.

```

æ˜¾ç„¶è·å–åˆ°äº†æˆ‘ä»¬çš„è®¾å¤‡ï¼Œå‰åæ‘„åƒå¤´ï¼Œå’Œéº¦å…‹é£ï¼›ä¸‹é¢æˆ‘ä»¬çœ‹çœ‹ç³»ç»Ÿè‡ªå¸¦çš„è·å–æ‘„åƒå¤´çš„ä¾‹å­ï¼š

## iOSç³»ç»Ÿè‡ªå¸¦è·å–æ‘„åƒå¤´

- é¦–å…ˆå¯¼å…¥å¿…é¡»çš„å¤´æ–‡ä»¶

```
#import <AVFoundation/AVFoundation.h>
#import <UIKit/UIKit.h>
```

- ç„¶åæ˜¯ä¸€äº›å…¨å±€çš„å±æ€§

```
@property(nonatomic, strong) AVCaptureSession                *captureSession;
@property(nonatomic, strong) AVCaptureDevice                 *captureDevice;
@property(nonatomic, strong) AVCaptureDeviceInput            *captureDeviceInput;
@property(nonatomic, strong) AVCaptureVideoDataOutput        *captureVideoDataOutput;
@property(nonatomic, assign) CGSize                          videoSize;
@property(nonatomic, strong) AVCaptureConnection             *videoCaptureConnection;
@property(nonatomic, strong) AVCaptureVideoPreviewLayer      *previewLayer;

```

-  æœ€åæ˜¯ç®€å•å°è£…çš„ä»£ç 

```
- (void)getMovieDevice:(UIView *)view{
    self.captureSession = [[AVCaptureSession alloc] init];
    //    captureSession.sessionPreset = AVCaptureSessionPresetMedium;
    self.captureSession.sessionPreset = AVCaptureSessionPreset1920x1080;
    
    self.videoSize = [self getVideoSize:self.captureSession.sessionPreset];
    
    self.captureDevice = [AVCaptureDevice defaultDeviceWithMediaType:AVMediaTypeVideo];
    
    NSError *error = nil;
    self.captureDeviceInput = [AVCaptureDeviceInput deviceInputWithDevice:self.captureDevice error:&error];
    
    if([self.captureSession canAddInput:self.captureDeviceInput])
        [self.captureSession addInput:self.captureDeviceInput];
    else
        NSLog(@"Error: %@", error);
    
    dispatch_queue_t queue = dispatch_queue_create("myEncoderH264Queue", NULL);
    
    self.captureVideoDataOutput = [[AVCaptureVideoDataOutput alloc] init];
    [self.captureVideoDataOutput setSampleBufferDelegate:self queue:queue];
    
#if encodeModel
    // nv12
    NSDictionary *settings = [[NSDictionary alloc] initWithObjectsAndKeys:
                              [NSNumber numberWithUnsignedInt:kCVPixelFormatType_420YpCbCr8BiPlanarFullRange],
                              kCVPixelBufferPixelFormatTypeKey,
                              nil];
#else
    // 32bgra
    NSDictionary *settings = [[NSDictionary alloc] initWithObjectsAndKeys:
                              [NSNumber numberWithUnsignedInt:kCVPixelFormatType_32BGRA],
                              kCVPixelBufferPixelFormatTypeKey,
                              nil];
#endif
    
    self.captureVideoDataOutput.videoSettings = settings;
    self.captureVideoDataOutput.alwaysDiscardsLateVideoFrames = YES;
    
    if ([self.captureSession canAddOutput:self.captureVideoDataOutput]) {
        [self.captureSession addOutput:self.captureVideoDataOutput];
    }
    
    // ä¿å­˜Connectionï¼Œç”¨äºåœ¨SampleBufferDelegateä¸­åˆ¤æ–­æ•°æ®æ¥æºï¼ˆæ˜¯Video/Audioï¼Ÿï¼‰
    self.videoCaptureConnection = [self.captureVideoDataOutput connectionWithMediaType:AVMediaTypeVideo];
    
#pragma mark -- AVCaptureVideoPreviewLayer init
    self.previewLayer = [AVCaptureVideoPreviewLayer layerWithSession:self.captureSession];
    self.previewLayer.frame = view.layer.bounds;
    self.previewLayer.videoGravity = AVLayerVideoGravityResizeAspectFill; // è®¾ç½®é¢„è§ˆæ—¶çš„è§†é¢‘ç¼©æ”¾æ–¹å¼
    [[self.previewLayer connection] setVideoOrientation:AVCaptureVideoOrientationPortrait]; // è®¾ç½®è§†é¢‘çš„æœå‘
    [self.captureSession startRunning];
    [view.layer addSublayer:self.previewLayer];
}

- (CGSize)getVideoSize:(NSString *)sessionPreset {
    CGSize size = CGSizeZero;
    if ([sessionPreset isEqualToString:AVCaptureSessionPresetMedium]) {
        size = CGSizeMake(480, 360);
    } else if ([sessionPreset isEqualToString:AVCaptureSessionPreset1920x1080]) {
        size = CGSizeMake(1920, 1080);
    } else if ([sessionPreset isEqualToString:AVCaptureSessionPreset1280x720]) {
        size = CGSizeMake(1280, 720);
    } else if ([sessionPreset isEqualToString:AVCaptureSessionPreset640x480]) {
        size = CGSizeMake(640, 480);
    }
    
    return size;
}

#pragma mark --  AVCaptureVideo(Audio)DataOutputSampleBufferDelegate method
- (void)captureOutput:(AVCaptureOutput *)captureOutput didOutputSampleBuffer:(CMSampleBufferRef)sampleBuffer fromConnection:(AVCaptureConnection *)connection
{
    
    // è¿™é‡Œçš„sampleBufferå°±æ˜¯é‡‡é›†åˆ°çš„æ•°æ®äº†ï¼Œä½†å®ƒæ˜¯Videoè¿˜æ˜¯Audioçš„æ•°æ®ï¼Œå¾—æ ¹æ®connectionæ¥åˆ¤æ–­
    if (connection == self.videoCaptureConnection) {
        
        // Video
        //        NSLog(@"åœ¨è¿™é‡Œè·å¾—video sampleBufferï¼Œåšè¿›ä¸€æ­¥å¤„ç†ï¼ˆç¼–ç H.264ï¼‰");
        
        
#if encodeModel
        // encode
        
#else
        CVPixelBufferRef pixelBuffer = CMSampleBufferGetImageBuffer(sampleBuffer);
        
        //        int pixelFormat = CVPixelBufferGetPixelFormatType(pixelBuffer);
        //        switch (pixelFormat) {
        //            case kCVPixelFormatType_420YpCbCr8BiPlanarVideoRange:
        //                NSLog(@"Capture pixel format=NV12");
        //                break;
        //            case kCVPixelFormatType_422YpCbCr8:
        //                NSLog(@"Capture pixel format=UYUY422");
        //                break;
        //            default:
        //                NSLog(@"Capture pixel format=RGB32");
        //                break;
        //        }
        
        CVPixelBufferLockBaseAddress(pixelBuffer, 0);
        
        // render
        [openglView render:pixelBuffer];
        
        CVPixelBufferUnlockBaseAddress(pixelBuffer, 0);
#endif
    }
    //    else if (connection == _audioConnection) {
    //        
    //        // Audio
    //        NSLog(@"è¿™é‡Œè·å¾—audio sampleBufferï¼Œåšè¿›ä¸€æ­¥å¤„ç†ï¼ˆç¼–ç AACï¼‰");
    //    }
    
}
```

[LBffmpegDemoä¸‹è½½åœ°å€](https://github.com/AllLuckly/LBffmpegDemo)

åˆ°æ­¤iOSå¹³å°è·å–æ‘„åƒå¤´å‘Šä¸€æ®µè½ï¼Œæœ‰æ—¶é—´å†æ…¢æ…¢å†™FFmpegåœ¨iOSå¹³å°çš„ä¸€äº›å…¶ä»–çš„ä½¿ç”¨æ–¹æ³•ï¼›æœ‰å¯¹ffmpegæ„Ÿå…´è¶£çš„æœ‹å‹å¯ä»¥å…³æ³¨æˆ‘ï¼ğŸ˜„



----------------------------------------------------------

> [åšä¸»appä¸Šçº¿å•¦ï¼Œå¿«ç‚¹æ­¤æ¥å›´è§‚å§](https://itunes.apple.com/us/app/it-blog-zi-xueios-kai-fa-jin/id1067787090?l=zh&ls=1&mt=8)<br>

> [æ›´å¤šç»éªŒè¯·ç‚¹å‡»](http://allluckly.cn)<br>

å¥½æ–‡æ¨èï¼š[ffmpeg-iOSæ¨æµå™¨](https://blog.allluckly.cn/ffmpeg/ffmpeg3/)<br>



